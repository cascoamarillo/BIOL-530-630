{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0e69a6d3",
   "metadata": {},
   "source": [
    "# Lab03\n",
    "## BLAST steps\n",
    "This notebook provides a simplified ground-level look at how BLASTP (Basic Local Alignment Search Tool for Proteins) functions.\n",
    "\n",
    "For the Activity 3:\n",
    "1) Run all the code. Make sure it works and you get the outputs\n",
    "2) Answer the question (x3) along the notebook\n",
    "3) Save the notebook with your name (not initials). Save as HTML and export as PDF. Then, submit the assignment to MyCourses."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7fff0987",
   "metadata": {},
   "source": [
    "### Our sample sequences (Amino Acids)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "56b0a938",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "query = \"HEAGAWGHEE\"\n",
    "database = \"PAWHEAELLGHEAGAWGHPA\"\n",
    "word_size = 3 \n",
    "\n",
    "print(f\"Query: {query}\")\n",
    "print(f\"Database: {database}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6b33a8c3",
   "metadata": {},
   "source": [
    "### Seeding (Word Generation & Indexing)\n",
    "\n",
    "The algorithm starts by breaking the query sequence into small \"words\" of a fixed size (here, k=3)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "09678a98",
   "metadata": {},
   "outputs": [],
   "source": [
    "def index_query(sequence, w):\n",
    "    words = {}\n",
    "    for i in range(len(sequence) - w + 1):\n",
    "        word = sequence[i:i+w]\n",
    "        if word not in words:\n",
    "            words[word] = []\n",
    "        words[word].append(i)\n",
    "    return words\n",
    "\n",
    "query_words = index_query(query, word_size)\n",
    "print(f\"Query words (Size {word_size}) and their indices:\")\n",
    "print(query_words)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4dbcdac9",
   "metadata": {},
   "source": [
    "### Scanning the Database\n",
    "\n",
    "The find_word_hits function scans the database for any occurrences of the words in your index. These matches are called seeds. This is a \"hit/no-hit\" phase that avoids expensive alignments."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0088a332",
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_word_hits(db, query_index, w):\n",
    "    hits = []\n",
    "    for i in range(len(db) - w + 1):\n",
    "        db_word = db[i:i+w]\n",
    "        if db_word in query_index:\n",
    "            # A word might appear multiple times in the query\n",
    "            for query_pos in query_index[db_word]:\n",
    "                hits.append({\n",
    "                    'word': db_word,\n",
    "                    'query_start': query_pos,\n",
    "                    'db_start': i\n",
    "                })\n",
    "    return hits\n",
    "\n",
    "hits = find_word_hits(database, query_words, word_size)\n",
    "\n",
    "# Visualizing the hits using a DataFrame\n",
    "import pandas as pd\n",
    "df_hits = pd.DataFrame(hits)\n",
    "print(\"\\nWord Matches (Seeds) Found:\")\n",
    "print(df_hits)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "da9a607f",
   "metadata": {},
   "source": [
    "### Scoring system\n",
    "\n",
    "A simplified mini-BLOSUM62 for our example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f27547b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# A simplified mini-BLOSUM62 for our example\n",
    "# (In a real scenario, you'd use a library like Bio.Align.substitution_matrices)\n",
    "scoring_matrix = {\n",
    "    # --- A (Alanine) ---\n",
    "    ('A', 'A'):  4, ('A', 'G'):  0, ('A', 'W'): -4, ('A', 'H'): -2, ('A', 'E'): -1,\n",
    "    \n",
    "    # --- G (Glycine) ---\n",
    "    ('G', 'A'):  0, ('G', 'G'):  4, ('G', 'W'): -4, ('G', 'H'): -2, ('G', 'E'): -1,\n",
    "    \n",
    "    # --- W (Tryptophan) ---\n",
    "    ('W', 'A'): -4, ('W', 'G'): -4, ('W', 'W'): 11, ('W', 'H'): -3, ('W', 'E'): -5,\n",
    "    \n",
    "    # --- H (Histidine) ---\n",
    "    ('H', 'A'): -2, ('H', 'G'): -2, ('H', 'W'): -3, ('H', 'H'):  8, ('H', 'E'):  0,\n",
    "    \n",
    "    # --- E (Glutamate) ---\n",
    "    ('E', 'A'): -1, ('E', 'G'): -1, ('E', 'W'): -5, ('E', 'H'):  0, ('E', 'E'):  5\n",
    "}\n",
    "\n",
    "def score_words(word1, word2):\n",
    "    score = 0\n",
    "    for a, b in zip(word1, word2):\n",
    "        score += scoring_matrix.get((a, b), -4) # Default to -4 for unknown pairs\n",
    "    return score"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "45b9589d",
   "metadata": {},
   "source": [
    "### Stablish Neighborhood table\n",
    "\n",
    "The get_neighborhood function is the \"secret sauce\" that makes BLAST a heuristic (approximate) search rather than a slow, literal search."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e4a42a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import itertools\n",
    "\n",
    "def get_neighborhood(query_word, threshold, alphabet):\n",
    "    neighbors = []\n",
    "    # Generate all possible words of the same length\n",
    "    for permutation in itertools.product(alphabet, repeat=len(query_word)):\n",
    "        candidate = \"\".join(permutation)\n",
    "        if score_words(query_word, candidate) >= threshold:\n",
    "            neighbors.append(candidate)\n",
    "    return neighbors\n",
    "\n",
    "# Example: Finding neighbors for the word \"HEA\"\n",
    "alphabet = \"AGWHE\" # Simplified for this demo\n",
    "word = \"HEA\"\n",
    "threshold = 11\n",
    "\n",
    "neighborhood = get_neighborhood(word, threshold, alphabet)\n",
    "print(f\"Neighbors for '{word}' with threshold {threshold}:\")\n",
    "print(neighborhood)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "40afdd4c",
   "metadata": {},
   "source": [
    "### Maps Neighbors to Positions\n",
    "\n",
    "The build_neighborhood_index function is the step that compiles all the \"neighbor\"  words into a searchable index for the entire query sequence."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d1f2455",
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_neighborhood_index(query, word_size, threshold, alphabet):\n",
    "    index = {}\n",
    "    for i in range(len(query) - word_size + 1):\n",
    "        actual_word = query[i:i+word_size]\n",
    "        neighbors = get_neighborhood(actual_word, threshold, alphabet)\n",
    "        \n",
    "        for neighbor in neighbors:\n",
    "            if neighbor not in index:\n",
    "                index[neighbor] = []\n",
    "            index[neighbor].append(i)\n",
    "    return index\n",
    "\n",
    "# Build the index with neighborhood logic\n",
    "neighborhood_index = build_neighborhood_index(query, word_size, 11, \"AGWHE\")\n",
    "\n",
    "# Re-run the scan on the database\n",
    "new_hits = find_word_hits(database, neighborhood_index, word_size)\n",
    "\n",
    "print(f\"\\nFound {len(new_hits)} hits using neighborhood logic (vs earlier exact matches).\")\n",
    "pd.DataFrame(new_hits).head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1139bba6",
   "metadata": {},
   "source": [
    "### Extension (HSP Generation)\n",
    "\n",
    "Once a seed is found, the extend_hit function tries to grow the alignment in both directions (left and right)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "327638be",
   "metadata": {},
   "outputs": [],
   "source": [
    "def extend_hit(query, db, q_start, db_start, word_size, matrix, drop_off):\n",
    "    # Initial score of the word match\n",
    "    current_score = score_words(query[q_start:q_start+word_size], \n",
    "                                db[db_start:db_start+word_size])\n",
    "    \n",
    "    max_score = current_score\n",
    "    \n",
    "    # Coordinates of the alignment\n",
    "    q_ext_start, q_ext_end = q_start, q_start + word_size\n",
    "    db_ext_start, db_ext_end = db_start, db_start + word_size\n",
    "    \n",
    "    # 1. Extend Right\n",
    "    i = 1\n",
    "    while (q_start + word_size + i <= len(query) and \n",
    "           db_start + word_size + i <= len(db)):\n",
    "        char_q = query[q_start + word_size + i - 1]\n",
    "        char_db = db[db_start + word_size + i - 1]\n",
    "        current_score += matrix.get((char_q, char_db), -4)\n",
    "        \n",
    "        if current_score > max_score:\n",
    "            max_score = current_score\n",
    "            q_ext_end = q_start + word_size + i\n",
    "            db_ext_end = db_start + word_size + i\n",
    "        \n",
    "        if current_score < (max_score - drop_off):\n",
    "            break\n",
    "        i += 1\n",
    "\n",
    "    # 2. Extend Left (reset current_score to max_score achieved during right extension)\n",
    "    current_score = max_score\n",
    "    i = 1\n",
    "    while (q_start - i >= 0 and db_start - i >= 0):\n",
    "        char_q = query[q_start - i]\n",
    "        char_db = db[db_start - i]\n",
    "        current_score += matrix.get((char_q, char_db), -4)\n",
    "        \n",
    "        if current_score > max_score:\n",
    "            max_score = current_score\n",
    "            q_ext_start = q_start - i\n",
    "            db_ext_start = db_start - i\n",
    "            \n",
    "        if current_score < (max_score - drop_off):\n",
    "            break\n",
    "        i += 1\n",
    "        \n",
    "    return {\n",
    "        'score': max_score,\n",
    "        'query_seq': query[q_ext_start:q_ext_end],\n",
    "        'db_seq': db[db_ext_start:db_ext_end],\n",
    "        'query_range': (q_ext_start, q_ext_end),\n",
    "        'db_range': (db_ext_start, db_ext_end)\n",
    "    }"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b52a2510",
   "metadata": {},
   "source": [
    "### Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "86f40fea",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_hsps = []\n",
    "drop_off = 2\n",
    "\n",
    "for hit in new_hits:\n",
    "    hsp = extend_hit(query, database, hit['query_start'], hit['db_start'], word_size, scoring_matrix, drop_off)\n",
    "    all_hsps.append(hsp)\n",
    "\n",
    "# Filter for unique HSPs and sort by score\n",
    "hsps_df = pd.DataFrame(all_hsps).drop_duplicates(subset=['query_seq', 'db_seq'])\n",
    "hsps_df = hsps_df.sort_values(by='score', ascending=False)\n",
    "\n",
    "print(\"High-scoring Segment Pairs (HSPs):\")\n",
    "hsps_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "100f3438",
   "metadata": {},
   "outputs": [],
   "source": [
    "def display_hsp(hsp):\n",
    "    # Extract data\n",
    "    q_seq = hsp['query_seq']\n",
    "    db_seq = hsp['db_seq']\n",
    "    q_start, q_end = hsp['query_range']\n",
    "    db_start, db_end = hsp['db_range']\n",
    "    \n",
    "    # Create the middle \"match\" line\n",
    "    # In BLAST, '|' is used for identity, '+' for similar, ' ' for mismatch\n",
    "    match_line = \"\"\n",
    "    for q_char, db_char in zip(q_seq, db_seq):\n",
    "        if q_char == db_char:\n",
    "            match_line += \"|\"\n",
    "        elif scoring_matrix.get((q_char, db_char), -4) > 0:\n",
    "            match_line += \"+\"\n",
    "        else:\n",
    "            match_line += \" \"\n",
    "\n",
    "    # Format with consistent widths for coordinates (e.g., 5 spaces)\n",
    "    print(f\"Score: {hsp['score']}\")\n",
    "    print(f\"Query  {q_start:<5} {q_seq} {q_end:>5}\")\n",
    "    print(f\"       {' ' * 5} {match_line}\")\n",
    "    print(f\"Sbjct  {db_start:<5} {db_seq} {db_end:>5}\\n\")\n",
    "\n",
    "# Re-run the display\n",
    "for _, row in hsps_df.head(2).iterrows():\n",
    "    display_hsp(row)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9e1aab26",
   "metadata": {},
   "source": [
    "# <font color=red> Activity 3 </font>\n",
    "\n",
    "Now that we have found our High-scoring Segment Pairs (HSPs), we need to know: Is this match actually interesting, or could it have happened by random chance?\n",
    "\n",
    "Complete the function below using the standard BLAST formula. Feel free to use the \"function\" template below or create a new code to implement the E-value formula in the results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a22d7bfd",
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "\n",
    "def calculate_e_value(score, query_len, db_len):\n",
    "    \"\"\"\n",
    "    Calculates the E-value (Expect value) for a given alignment.\n",
    "    \"\"\"\n",
    "    # Constants for BLOSUM62 / Word-size 3\n",
    "    # These are typically pre-calculated by NCBI\n",
    "    Lambda = 0.267\n",
    "    K = 0.041\n",
    "    \n",
    "    # --- STUDENT TASK: IMPLEMENT THE FORMULA BELOW ---\n",
    "    # m = query_len\n",
    "    # n = db_len\n",
    "    # S = score\n",
    "    # Hint: Use math.exp() for the exponential part\n",
    "    \n",
    "    e_value = # ... [check your lecture slides for the formula] ...\n",
    "    \n",
    "    return e_value\n",
    "\n",
    "# Apply the calculation to our results table\n",
    "query_len = len(query)\n",
    "db_len = len(database)\n",
    "\n",
    "# Use a lambda function to apply your calculation to every row in the dataframe\n",
    "hsps_df['E-value'] = hsps_df['score'].apply(lambda s: calculate_e_value(s, query_len, db_len))\n",
    "\n",
    "print(\"Final BLAST Results with E-values:\")\n",
    "# Displaying the most important columns\n",
    "display(hsps_df[['score', 'E-value', 'query_seq', 'db_seq']].sort_values(by='score', ascending=False))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "53b73c26",
   "metadata": {},
   "source": [
    "### Full HSP Extension Plot\n",
    "\n",
    "This code will capture the score progression in both directions and center the \"seed\" at the middle of the graph.\n",
    "\n",
    "The Orange Line: Represents the original 3-letter word (seed) found during the scanning phase.\n",
    "\n",
    "The Green line: Shows the \"High-scoring Segment Pair\" (HSP). If the sequences are highly similar, this peak will stay high for a long time.\n",
    "\n",
    "The Red Dotted Line: The \"Drop-off\" boundary. This is the mathematical \"patience\" of the algorithm; once the teal line stays below this red line, the search for this specific segment stops."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1148b41a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "def run_and_plot_blast_full(query, database, word_size=3, drop_off=5):\n",
    "    # 1. Get the first hit\n",
    "    query_index = index_query(query, word_size)\n",
    "    hits = find_word_hits(database, query_index, word_size)\n",
    "    \n",
    "    if not hits:\n",
    "        print(\"No hits found!\")\n",
    "        return\n",
    "    \n",
    "    hit = hits[0]\n",
    "    q_start, db_start = hit['query_start'], hit['db_start']\n",
    "    \n",
    "    # Initial seed score\n",
    "    seed_score = score_words(query[q_start:q_start+word_size], database[db_start:db_start+word_size])\n",
    "    \n",
    "    # 2. Extend Right\n",
    "    right_scores = []\n",
    "    current_score = seed_score\n",
    "    max_score_right = seed_score\n",
    "    i = 1\n",
    "    while (q_start + word_size + i <= len(query) and db_start + word_size + i <= len(database)):\n",
    "        char_q = query[q_start + word_size + i - 1]\n",
    "        char_db = database[db_start + word_size + i - 1]\n",
    "        current_score += scoring_matrix.get((char_q, char_db), -4)\n",
    "        right_scores.append(current_score)\n",
    "        if current_score > max_score_right: max_score_right = current_score\n",
    "        if current_score < (max_score_right - drop_off): break\n",
    "        i += 1\n",
    "\n",
    "    # 3. Extend Left\n",
    "    left_scores = []\n",
    "    current_score = seed_score\n",
    "    max_score_left = seed_score\n",
    "    i = 1\n",
    "    while (q_start - i >= 0 and db_start - i >= 0):\n",
    "        char_q = query[q_start - i]\n",
    "        char_db = database[db_start - i]\n",
    "        current_score += scoring_matrix.get((char_q, char_db), -4)\n",
    "        left_scores.insert(0, current_score) # Insert at start to keep sequence order\n",
    "        if current_score > max_score_left: max_score_left = current_score\n",
    "        if current_score < (max_score_left - drop_off): break\n",
    "        i += 1\n",
    "\n",
    "    # Combine: Left scores + Seed score + Right scores\n",
    "    full_scores = left_scores + [seed_score] + right_scores\n",
    "    seed_index = len(left_scores)\n",
    "    \n",
    "    # 4. Plotting\n",
    "    plt.figure(figsize=(10, 5))\n",
    "    plt.plot(full_scores, marker='o', linestyle='-', color='green', label='Alignment Score')\n",
    "    plt.axvline(x=seed_index, color='orange', linestyle='--', label='Seed Position')\n",
    "    \n",
    "    # Threshold line based on the global maximum\n",
    "    global_max = max(full_scores)\n",
    "    plt.axhline(y=global_max - drop_off, color='red', linestyle=':', label='Termination Threshold')\n",
    "    \n",
    "    plt.title(f\"Full BLAST Extension: '{query[q_start:q_start+word_size]}' at Query Index {q_start}\")\n",
    "    plt.xlabel(\"Relative Alignment Position\")\n",
    "    plt.ylabel(\"Score\")\n",
    "    plt.legend()\n",
    "    plt.grid(alpha=0.3)\n",
    "    plt.show()\n",
    "\n",
    "run_and_plot_blast_full(query, database)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9ae6574c",
   "metadata": {},
   "source": [
    "# <font color=red> Activity 3 </font>\n",
    "Run the notebook multiple times while varying one parameter at a time:\n",
    "\n",
    "- Word size (word_size)\n",
    "- Threshold (threshold)\n",
    "\n",
    "Explain (and document) how changes in each parameter affect the balance between search speed and biological sensitivity, and how this is reflected in the alignments obtained.\n",
    "\n",
    "## Answer\n",
    "Type your answer (text) here."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ba7c70d1",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "71be3e92",
   "metadata": {},
   "source": [
    "# <font color=red> Activity 3 </font>\n",
    "The \"X-Factor\" (Drop-off Threshold)\n",
    "You are comparing two sequences that start identically but diverge significantly in the middle before matching again at the very end:\n",
    "\n",
    "    Query: HHHAGWWHHH\n",
    "\n",
    "    Database: HHHAGAAAHH\n",
    "\n",
    "Learn how the Drop-off setting acts as the algorithm's \"patience.\" The Drop-off value is a \"cutoff\" point. It tells BLAST: \"If the score falls too far below the highest peak we found, stop searching.\"\n",
    "\n",
    "Using the cell code below, find two values for Drop-off (drop_off = X) settings in the algorithm where:\n",
    " \n",
    "    -Finds a match only with the first region\n",
    "    -Extends to the full sequence\n",
    "\n",
    "And plot the respective HSP extensions.\n",
    "\n",
    "Hint: WW (Tryptophans) in the query are replaced by AA (Alanines) in the database. According to our scoring_matrix, this mismatch is a heavy penalty (-4 points per letter)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f68e38b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1. Define the sequences\n",
    "query_seq = \"HHHAGWWHHH\"\n",
    "db_seq    = \"HHHAGAAAHH\"\n",
    "\n",
    "# 2. Run the experiment\n",
    "print(\"--- TEST A: Low Patience (drop_off = X) ---\")\n",
    "run_and_plot_blast_full(query_seq, db_seq, word_size=3, drop_off=X)\n",
    "\n",
    "print(\"--- TEST B: High Patience (drop_off = X) ---\")\n",
    "run_and_plot_blast_full(query_seq, db_seq, word_size=3, drop_off=X)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
